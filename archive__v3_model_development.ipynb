{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data: (1190, 2)\n",
      "val_data: (173, 2)\n",
      "test_data: (338, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import sacrebleu\n",
    "from rouge_score import rouge_scorer\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "############ 1. Data Preparation for Model Training by Combine the datasets and prepare them for training ############\n",
    "# Load cleaned Counsel-Chat dataset\n",
    "counsel_chat_data = pd.read_csv(\n",
    "    '/Users/dipendrapant/Library/CloudStorage/OneDrive-NTNU/ForFun/npj_digital_medicine/code/data/counsel_chat_data_after_data_preparation.csv')\n",
    "display(counsel_chat_data.info())\n",
    "display(counsel_chat_data.head(4))\n",
    "# Rename columns for consistency with previous combined data format\n",
    "counsel_chat_data.rename(\n",
    "    columns={'questionText': 'prompt', 'answerText': 'response'}, inplace=True)\n",
    "############ 1. Generate Responses Using GPT-4 Model via OpenAI API ############\n",
    "\n",
    "openai.api_key = 'sk-proj-6TLzq89EwvduXuziOOVDT3BlbkFJ1TqCRGrTSdnVF1oDysKl'\n",
    "\n",
    "\n",
    "def generate_responses(data, model_name='gpt-4'):\n",
    "    responses = []\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        prompt = row['prompt']\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=model_name,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a mental health counselor.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                max_tokens=150,\n",
    "                temperature=0.7\n",
    "            )\n",
    "            responses.append(response.choices[0].message['content'].strip())\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating response for index {index}: {e}\")\n",
    "            responses.append(\"\")\n",
    "\n",
    "    data['generated_response'] = responses\n",
    "    data.to_csv('/Users/dipendrapant/Library/CloudStorage/OneDrive-NTNU/ForFun/npj_digital_medicine/code/data/result/v3/generated_responses.csv', index=False)\n",
    "    return data\n",
    "\n",
    "\n",
    "# Generate responses for the dataset\n",
    "counsel_chat_data = generate_responses(counsel_chat_data)\n",
    "\n",
    "############ 2. Evaluation of Generated Responses ############\n",
    "\n",
    "\n",
    "def evaluate_responses(data):\n",
    "    bleu_scores = []\n",
    "    rouge_scores = {'rouge1': [], 'rouge2': [], 'rougeL': []}\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        reference = row['response']\n",
    "        hypothesis = row['generated_response']\n",
    "\n",
    "        try:\n",
    "            # BLEU Score\n",
    "            bleu_score = sacrebleu.sentence_bleu(\n",
    "                hypothesis, [reference]).score / 100  # Normalize BLEU score\n",
    "            bleu_scores.append(bleu_score)\n",
    "\n",
    "            # ROUGE Score\n",
    "            scorer = rouge_scorer.RougeScorer(\n",
    "                ['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "            scores = scorer.score(reference, hypothesis)\n",
    "            for key in scores:\n",
    "                rouge_scores[key].append(scores[key].fmeasure)\n",
    "\n",
    "            print(f\"Processed index {index}: BLEU = {bleu_score}, ROUGE-1 = {scores['rouge1'].fmeasure}, ROUGE-2 = {\n",
    "                  scores['rouge2'].fmeasure}, ROUGE-L = {scores['rougeL'].fmeasure}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing index {index}: {e}\")\n",
    "\n",
    "    evaluation_results = {\n",
    "        'bleu': sum(bleu_scores) / len(bleu_scores) if bleu_scores else 0,\n",
    "        'rouge1': sum(rouge_scores['rouge1']) / len(rouge_scores['rouge1']) if rouge_scores['rouge1'] else 0,\n",
    "        'rouge2': sum(rouge_scores['rouge2']) / len(rouge_scores['rouge2']) if rouge_scores['rouge2'] else 0,\n",
    "        'rougeL': sum(rouge_scores['rougeL']) / len(rouge_scores['rougeL']) if rouge_scores['rougeL'] else 0\n",
    "    }\n",
    "\n",
    "    return evaluation_results\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "evaluation_results = evaluate_responses(\n",
    "    '/Users/dipendrapant/Library/CloudStorage/OneDrive-NTNU/ForFun/npj_digital_medicine/code/data/result/v3/generated_responses.csv')\n",
    "print(\"Evaluation Results:\", evaluation_results)\n",
    "\n",
    "############ 3. Analyze BLEU Score Distribution ############\n",
    "\n",
    "\n",
    "def calculate_bleu_scores(data):\n",
    "    bleu_scores = []\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        reference = row['response']\n",
    "        hypothesis = row['generated_response']\n",
    "        bleu_score = sacrebleu.sentence_bleu(hypothesis, [reference]).score\n",
    "        bleu_scores.append(bleu_score)\n",
    "\n",
    "    data['bleu_score'] = bleu_scores\n",
    "    return data\n",
    "\n",
    "\n",
    "evaluated_data = calculate_bleu_scores(\n",
    "    '/Users/dipendrapant/Library/CloudStorage/OneDrive-NTNU/ForFun/npj_digital_medicine/code/data/result/v3/generated_responses.csv')\n",
    "\n",
    "# Plot Distribution:\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(evaluated_data['bleu_score'], bins=50,\n",
    "         color='skyblue', edgecolor='black', alpha=0.5)\n",
    "plt.title('Distribution of BLEU Scores')\n",
    "plt.xlabel('BLEU Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.savefig('/Users/dipendrapant/Library/CloudStorage/OneDrive-NTNU/ForFun/npj_digital_medicine/code/data/result/v3/bleu_score_distribution.eps', format='eps', dpi=600)\n",
    "plt.show()\n",
    "\n",
    "############ 4. Length Analysis of Generated Responses ############\n",
    "\n",
    "evaluated_data['reference_length'] = evaluated_data['response'].apply(len)\n",
    "evaluated_data['generated_length'] = evaluated_data['generated_response'].apply(\n",
    "    len)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(evaluated_data.index,\n",
    "            evaluated_data['reference_length'], color='blue', label='Reference Response Length')\n",
    "plt.scatter(evaluated_data.index,\n",
    "            evaluated_data['generated_length'], color='orange', label='Generated Response Length')\n",
    "\n",
    "plt.xlabel('Data Index')\n",
    "plt.ylabel('Response Length')\n",
    "plt.title('Length Comparison of Reference and Generated Responses')\n",
    "plt.legend()\n",
    "plt.savefig('/Users/dipendrapant/Library/CloudStorage/OneDrive-NTNU/ForFun/npj_digital_medicine/code/data/result/v3/length_analysis.eps', format='eps', dpi=600)\n",
    "plt.show()\n",
    "\n",
    "############ 5. Content Analysis of Generated Responses ############\n",
    "\n",
    "generated_responses = evaluated_data['generated_response'].tolist()\n",
    "word_counts = Counter(\" \".join(generated_responses).split())\n",
    "\n",
    "common_words = word_counts.most_common(20)\n",
    "print(\"Most common words in generated responses:\")\n",
    "for word, count in common_words:\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import sacrebleu\n",
    "from rouge_score import rouge_scorer\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "############ 1. Data Preparation for Model Training by Combine the datasets and prepare them for training ############\n",
    "# Load cleaned Counsel-Chat dataset\n",
    "counsel_chat_data = pd.read_csv(\n",
    "    '/Users/dipendrapant/Library/CloudStorage/OneDrive-NTNU/ForFun/npj_digital_medicine/code/data/counsel_chat_data_after_data_preparation.csv')\n",
    "display(counsel_chat_data.info())\n",
    "display(counsel_chat_data.head(4))\n",
    "# Rename columns for consistency with previous combined data format\n",
    "counsel_chat_data.rename(\n",
    "    columns={'questionText': 'prompt', 'answerText': 'response'}, inplace=True)\n",
    "############ 1. Generate Responses Using GPT-4 Model via OpenAI API ############\n",
    "\n",
    "openai.api_key = 'key_here'\n",
    "\n",
    "\n",
    "def generate_responses(data, model_name='gpt-4'):\n",
    "    responses = []\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        prompt = row['prompt']\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=model_name,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a mental health counselor.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                max_tokens=150,\n",
    "                temperature=0.7\n",
    "            )\n",
    "            responses.append(response.choices[0].message['content'].strip())\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating response for index {index}: {e}\")\n",
    "            responses.append(\"\")\n",
    "\n",
    "    data['generated_response'] = responses\n",
    "    data.to_csv('/Users/dipendrapant/Library/CloudStorage/OneDrive-NTNU/ForFun/npj_digital_medicine/code/data/result/v3/generated_responses.csv', index=False)\n",
    "    return data\n",
    "\n",
    "\n",
    "# Generate responses for the dataset\n",
    "counsel_chat_data = generate_responses(counsel_chat_data)\n",
    "\n",
    "############ 2. Evaluation of Generated Responses ############\n",
    "\n",
    "\n",
    "def evaluate_responses(data):\n",
    "    bleu_scores = []\n",
    "    rouge_scores = {'rouge1': [], 'rouge2': [], 'rougeL': []}\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        reference = row['response']\n",
    "        hypothesis = row['generated_response']\n",
    "\n",
    "        try:\n",
    "            # BLEU Score\n",
    "            bleu_score = sacrebleu.sentence_bleu(\n",
    "                hypothesis, [reference]).score / 100  # Normalize BLEU score\n",
    "            bleu_scores.append(bleu_score)\n",
    "\n",
    "            # ROUGE Score\n",
    "            scorer = rouge_scorer.RougeScorer(\n",
    "                ['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "            scores = scorer.score(reference, hypothesis)\n",
    "            for key in scores:\n",
    "                rouge_scores[key].append(scores[key].fmeasure)\n",
    "\n",
    "            print(f\"Processed index {index}: BLEU = {bleu_score}, ROUGE-1 = {scores['rouge1'].fmeasure}, ROUGE-2 = {\n",
    "                  scores['rouge2'].fmeasure}, ROUGE-L = {scores['rougeL'].fmeasure}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing index {index}: {e}\")\n",
    "\n",
    "    evaluation_results = {\n",
    "        'bleu': sum(bleu_scores) / len(bleu_scores) if bleu_scores else 0,\n",
    "        'rouge1': sum(rouge_scores['rouge1']) / len(rouge_scores['rouge1']) if rouge_scores['rouge1'] else 0,\n",
    "        'rouge2': sum(rouge_scores['rouge2']) / len(rouge_scores['rouge2']) if rouge_scores['rouge2'] else 0,\n",
    "        'rougeL': sum(rouge_scores['rougeL']) / len(rouge_scores['rougeL']) if rouge_scores['rougeL'] else 0\n",
    "    }\n",
    "\n",
    "    return evaluation_results\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "evaluation_results = evaluate_responses(\n",
    "    '/Users/dipendrapant/Library/CloudStorage/OneDrive-NTNU/ForFun/npj_digital_medicine/code/data/result/v3/generated_responses.csv')\n",
    "print(\"Evaluation Results:\", evaluation_results)\n",
    "\n",
    "############ 3. Analyze BLEU Score Distribution ############\n",
    "\n",
    "\n",
    "def calculate_bleu_scores(data):\n",
    "    bleu_scores = []\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        reference = row['response']\n",
    "        hypothesis = row['generated_response']\n",
    "        bleu_score = sacrebleu.sentence_bleu(hypothesis, [reference]).score\n",
    "        bleu_scores.append(bleu_score)\n",
    "\n",
    "    data['bleu_score'] = bleu_scores\n",
    "    return data\n",
    "\n",
    "\n",
    "evaluated_data = calculate_bleu_scores(\n",
    "    '/Users/dipendrapant/Library/CloudStorage/OneDrive-NTNU/ForFun/npj_digital_medicine/code/data/result/v3/generated_responses.csv')\n",
    "\n",
    "# Plot Distribution:\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(evaluated_data['bleu_score'], bins=50,\n",
    "         color='skyblue', edgecolor='black', alpha=0.5)\n",
    "plt.title('Distribution of BLEU Scores')\n",
    "plt.xlabel('BLEU Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.savefig('/Users/dipendrapant/Library/CloudStorage/OneDrive-NTNU/ForFun/npj_digital_medicine/code/data/result/v3/bleu_score_distribution.eps', format='eps', dpi=600)\n",
    "plt.show()\n",
    "\n",
    "############ 4. Length Analysis of Generated Responses ############\n",
    "\n",
    "evaluated_data['reference_length'] = evaluated_data['response'].apply(len)\n",
    "evaluated_data['generated_length'] = evaluated_data['generated_response'].apply(\n",
    "    len)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(evaluated_data.index,\n",
    "            evaluated_data['reference_length'], color='blue', label='Reference Response Length')\n",
    "plt.scatter(evaluated_data.index,\n",
    "            evaluated_data['generated_length'], color='orange', label='Generated Response Length')\n",
    "\n",
    "plt.xlabel('Data Index')\n",
    "plt.ylabel('Response Length')\n",
    "plt.title('Length Comparison of Reference and Generated Responses')\n",
    "plt.legend()\n",
    "plt.savefig('/Users/dipendrapant/Library/CloudStorage/OneDrive-NTNU/ForFun/npj_digital_medicine/code/data/result/v3/length_analysis.eps', format='eps', dpi=600)\n",
    "plt.show()\n",
    "\n",
    "############ 5. Content Analysis of Generated Responses ############\n",
    "\n",
    "generated_responses = evaluated_data['generated_response'].tolist()\n",
    "word_counts = Counter(\" \".join(generated_responses).split())\n",
    "\n",
    "common_words = word_counts.most_common(20)\n",
    "print(\"Most common words in generated responses:\")\n",
    "for word, count in common_words:\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1383 entries, 0 to 1382\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   questionID     1383 non-null   object\n",
      " 1   questionTitle  1383 non-null   object\n",
      " 2   questionText   1383 non-null   object\n",
      " 3   questionUrl    1383 non-null   object\n",
      " 4   topics         1376 non-null   object\n",
      " 5   therapistName  1383 non-null   object\n",
      " 6   therapistUrl   1383 non-null   object\n",
      " 7   answerText     1383 non-null   object\n",
      " 8   upvotes        1383 non-null   int64 \n",
      "dtypes: int64(1), object(8)\n",
      "memory usage: 97.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questionID</th>\n",
       "      <th>questionTitle</th>\n",
       "      <th>questionText</th>\n",
       "      <th>questionUrl</th>\n",
       "      <th>topics</th>\n",
       "      <th>therapistName</th>\n",
       "      <th>therapistUrl</th>\n",
       "      <th>answerText</th>\n",
       "      <th>upvotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5566fab2a64752d71ec3ca69</td>\n",
       "      <td>Escalating disagreements between mother and wife</td>\n",
       "      <td>my wife and mother are having tense disagreeme...</td>\n",
       "      <td>https://counselchat.com/questions/escalating-d...</td>\n",
       "      <td>Family Conflict</td>\n",
       "      <td>Kristi King-Morgan, LMSW</td>\n",
       "      <td>https://counselchat.com/therapists/kristi-king...</td>\n",
       "      <td>&lt;p&gt;what you are describing is something psycho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5566f94fa64752d71ec3ca64</td>\n",
       "      <td>I'm addicted to smoking. How can I stop?</td>\n",
       "      <td>i'm planning to have baby, so i have to quit s...</td>\n",
       "      <td>https://counselchat.com/questions/i-m-addicted...</td>\n",
       "      <td>Substance Abuse,Addiction</td>\n",
       "      <td>Rebecca Duellman</td>\n",
       "      <td>https://counselchat.com/therapists/rebecca-due...</td>\n",
       "      <td>&lt;p&gt;hi. good for you in planning ahead to do wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5567d26887a1cc0c3f3d8f46</td>\n",
       "      <td>Keeping secrets from my family</td>\n",
       "      <td>i have secrets in my mind, and i don't know wh...</td>\n",
       "      <td>https://counselchat.com/questions/keeping-secr...</td>\n",
       "      <td>Family Conflict</td>\n",
       "      <td>Jeevna Bajaj</td>\n",
       "      <td>https://counselchat.com/therapists/jeevna-bajaj</td>\n",
       "      <td>&lt;p&gt;it sounds like keeping the secrets has beco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>556bed15c969ba5861709df5</td>\n",
       "      <td>The Underlying Causes of Being Possessive</td>\n",
       "      <td>i am extremely possessive in my relationships ...</td>\n",
       "      <td>https://counselchat.com/questions/the-underlyi...</td>\n",
       "      <td>Behavioral Change,Social Relationships</td>\n",
       "      <td>Rebecca Duellman</td>\n",
       "      <td>https://counselchat.com/therapists/rebecca-due...</td>\n",
       "      <td>&lt;p&gt;hi there. it's great you are able to realiz...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 questionID                                     questionTitle  \\\n",
       "0  5566fab2a64752d71ec3ca69  Escalating disagreements between mother and wife   \n",
       "1  5566f94fa64752d71ec3ca64          I'm addicted to smoking. How can I stop?   \n",
       "2  5567d26887a1cc0c3f3d8f46                    Keeping secrets from my family   \n",
       "3  556bed15c969ba5861709df5         The Underlying Causes of Being Possessive   \n",
       "\n",
       "                                        questionText  \\\n",
       "0  my wife and mother are having tense disagreeme...   \n",
       "1  i'm planning to have baby, so i have to quit s...   \n",
       "2  i have secrets in my mind, and i don't know wh...   \n",
       "3  i am extremely possessive in my relationships ...   \n",
       "\n",
       "                                         questionUrl  \\\n",
       "0  https://counselchat.com/questions/escalating-d...   \n",
       "1  https://counselchat.com/questions/i-m-addicted...   \n",
       "2  https://counselchat.com/questions/keeping-secr...   \n",
       "3  https://counselchat.com/questions/the-underlyi...   \n",
       "\n",
       "                                   topics             therapistName  \\\n",
       "0                         Family Conflict  Kristi King-Morgan, LMSW   \n",
       "1               Substance Abuse,Addiction          Rebecca Duellman   \n",
       "2                         Family Conflict              Jeevna Bajaj   \n",
       "3  Behavioral Change,Social Relationships          Rebecca Duellman   \n",
       "\n",
       "                                        therapistUrl  \\\n",
       "0  https://counselchat.com/therapists/kristi-king...   \n",
       "1  https://counselchat.com/therapists/rebecca-due...   \n",
       "2    https://counselchat.com/therapists/jeevna-bajaj   \n",
       "3  https://counselchat.com/therapists/rebecca-due...   \n",
       "\n",
       "                                          answerText  upvotes  \n",
       "0  <p>what you are describing is something psycho...        0  \n",
       "1  <p>hi. good for you in planning ahead to do wh...        0  \n",
       "2  <p>it sounds like keeping the secrets has beco...        0  \n",
       "3  <p>hi there. it's great you are able to realiz...        0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import sacrebleu\n",
    "from rouge_score import rouge_scorer\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "############ 1. Data Preparation for Model Training by Combine the datasets and prepare them for training ############\n",
    "# Load cleaned Counsel-Chat dataset\n",
    "counsel_chat_data = pd.read_csv(\n",
    "    '/Users/dipendrapant/Library/CloudStorage/OneDrive-NTNU/ForFun/npj_digital_medicine/code/data/counsel_chat_data_after_data_preparation.csv')\n",
    "display(counsel_chat_data.info())\n",
    "display(counsel_chat_data.head(4))\n",
    "# Rename columns for consistency with previous combined data format\n",
    "counsel_chat_data.rename(\n",
    "    columns={'questionText': 'prompt', 'answerText': 'response'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ 2. Generate Responses Using GPT-4 Model via OpenAI API ############\n",
    "\n",
    "openai.api_key = 'sk-proj-6TLzq89EwvduXuziOOVDT3BlbkFJ1TqCRGrTSdnVF1oDysKl'\n",
    "\n",
    "\n",
    "def generate_responses(data, model_name='gpt-4'):\n",
    "    responses = []\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        prompt = row['prompt']\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=model_name,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a mental health counselor. Your goal is to provide empathetic, supportive, and reflective responses to clients' questions. Focus on understanding the clients' concerns and offering thoughtful and compassionate guidance.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                max_tokens=150,\n",
    "                temperature=0.7\n",
    "            )\n",
    "            responses.append(response.choices[0].message['content'].strip())\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating response for index {index}: {e}\")\n",
    "            responses.append(\"\")\n",
    "\n",
    "    data['generated_response'] = responses\n",
    "    data.to_csv('/Users/dipendrapant/Library/CloudStorage/OneDrive-NTNU/ForFun/npj_digital_medicine/code/data/result/v3/generated_responses.csv', index=False)\n",
    "    return data\n",
    "\n",
    "\n",
    "# Generate responses for the dataset\n",
    "counsel_chat_data = generate_responses(counsel_chat_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ 2. Evaluation of Generated Responses ############\n",
    "\n",
    "def evaluate_responses(data):\n",
    "    bleu_scores = []\n",
    "    rouge_scores = {'rouge1': [], 'rouge2': [], 'rougeL': []}\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        reference = row['response']\n",
    "        hypothesis = row['generated_response']\n",
    "\n",
    "        try:\n",
    "            # BLEU Score\n",
    "            bleu_score = sacrebleu.sentence_bleu(\n",
    "                hypothesis, [reference]).score / 100  # Normalize BLEU score\n",
    "            bleu_scores.append(bleu_score)\n",
    "\n",
    "            # ROUGE Score\n",
    "            scorer = rouge_scorer.RougeScorer(\n",
    "                ['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "            scores = scorer.score(reference, hypothesis)\n",
    "            for key in scores:\n",
    "                rouge_scores[key].append(scores[key].fmeasure)\n",
    "\n",
    "            print(f\"Processed index {index}: BLEU = {bleu_score}, ROUGE-1 = {scores['rouge1'].fmeasure}, ROUGE-2 = {\n",
    "                  scores['rouge2'].fmeasure}, ROUGE-L = {scores['rougeL'].fmeasure}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing index {index}: {e}\")\n",
    "\n",
    "    evaluation_results = {\n",
    "        'bleu': sum(bleu_scores) / len(bleu_scores) if bleu_scores else 0,\n",
    "        'rouge1': sum(rouge_scores['rouge1']) / len(rouge_scores['rouge1']) if rouge_scores['rouge1'] else 0,\n",
    "        'rouge2': sum(rouge_scores['rouge2']) / len(rouge_scores['rouge2']) if rouge_scores['rouge2'] else 0,\n",
    "        'rougeL': sum(rouge_scores['rougeL']) / len(rouge_scores['rougeL']) if rouge_scores['rougeL'] else 0\n",
    "    }\n",
    "\n",
    "    return evaluation_results\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "evaluation_results = evaluate_responses(\n",
    "    '/Users/dipendrapant/Library/CloudStorage/OneDrive-NTNU/ForFun/npj_digital_medicine/code/data/result/v3/generated_responses.csv')\n",
    "print(\"Evaluation Results:\", evaluation_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ 3. Analyze BLEU Score Distribution ############\n",
    "\n",
    "def calculate_bleu_scores(data):\n",
    "    bleu_scores = []\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        reference = row['response']\n",
    "        hypothesis = row['generated_response']\n",
    "        bleu_score = sacrebleu.sentence_bleu(hypothesis, [reference]).score\n",
    "        bleu_scores.append(bleu_score)\n",
    "\n",
    "    data['bleu_score'] = bleu_scores\n",
    "    return data\n",
    "\n",
    "\n",
    "evaluated_data = calculate_bleu_scores(\n",
    "    '/Users/dipendrapant/Library/CloudStorage/OneDrive-NTNU/ForFun/npj_digital_medicine/code/data/result/v3/generated_responses.csv')\n",
    "\n",
    "# Plot Distribution:\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(evaluated_data['bleu_score'], bins=50,\n",
    "         color='skyblue', edgecolor='black', alpha=0.5)\n",
    "plt.title('Distribution of BLEU Scores')\n",
    "plt.xlabel('BLEU Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.savefig('/Users/dipendrapant/Library/CloudStorage/OneDrive-NTNU/ForFun/npj_digital_medicine/code/data/result/v3/bleu_score_distribution.eps', format='eps', dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ 4. Length Analysis of Generated Responses ############\n",
    "\n",
    "evaluated_data['reference_length'] = evaluated_data['response'].apply(len)\n",
    "evaluated_data['generated_length'] = evaluated_data['generated_response'].apply(\n",
    "    len)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(evaluated_data.index,\n",
    "            evaluated_data['reference_length'], color='blue', label='Reference Response Length')\n",
    "plt.scatter(evaluated_data.index,\n",
    "            evaluated_data['generated_length'], color='orange', label='Generated Response Length')\n",
    "\n",
    "plt.xlabel('Data Index')\n",
    "plt.ylabel('Response Length')\n",
    "plt.title('Length Comparison of Reference and Generated Responses')\n",
    "plt.legend()\n",
    "plt.savefig('/Users/dipendrapant/Library/CloudStorage/OneDrive-NTNU/ForFun/npj_digital_medicine/code/data/result/v3/length_analysis.eps', format='eps', dpi=600)\n",
    "plt.show()\n",
    "\n",
    "############ 5. Content Analysis of Generated Responses ############\n",
    "\n",
    "generated_responses = evaluated_data['generated_response'].tolist()\n",
    "word_counts = Counter(\" \".join(generated_responses).split())\n",
    "\n",
    "common_words = word_counts.most_common(20)\n",
    "print(\"Most common words in generated responses:\")\n",
    "for word, count in common_words:\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Revised Article Sections:\n",
    "\n",
    "Abstract: Include the sentiment analysis and emotion detection results, highlighting their importance in evaluating the emotional tone and specific emotions in the generated responses.\n",
    "\n",
    "Introduction: Mention the addition of sentiment analysis and emotion detection as part of the evaluation process to better understand the emotional quality of the AI-generated responses.\n",
    "\n",
    "Methods: Detail the implementation of sentiment analysis and emotion detection, including the libraries and methods used.\n",
    "\n",
    "Results: Present the findings from the sentiment analysis and emotion detection, discussing how they complement the BLEU and ROUGE scores in assessing the quality of the generated responses.\n",
    "\n",
    "Discussion: Reflect on the implications of the sentiment and emotion analysis results for the use of AI in mental health counseling. Discuss how these results align with the call for papers’ focus on clinically applicable and ethically sound AI research.\n",
    "\n",
    "Limitations and Future Work: Acknowledge the limitations of the current study, such as the need for more nuanced measures of empathy and understanding beyond sentiment and emotion analysis. Suggest future research directions, including the development of models that can adapt to individual client needs and provide personalized responses.\n",
    "\n",
    "Conclusion: Summarize the study’s findings, including the sentiment and emotion analysis results, and emphasize the potential of AI to support mental health counseling while highlighting the need for further research to enhance its effectiveness.\n",
    "\n",
    "Ensure that all references and citations are correctly formatted according to the Nature Portfolio submission guidelines. By incorporating these changes, the article will be more comprehensive and aligned with the call for papers’ requirements. Remember to include a discussion on the ethical considerations of using AI in mental health care, as emphasized in the call for papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "############ 6. Sentiment Analysis and Emotion Detection ############\n",
    "\n",
    "# Function to perform sentiment analysis\n",
    "\n",
    "\n",
    "def analyze_sentiment(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "# Function to perform emotion detection\n",
    "\n",
    "\n",
    "def detect_emotions(text):\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    return sid.polarity_scores(text)\n",
    "\n",
    "# Adding sentiment analysis and emotion detection to the evaluation\n",
    "\n",
    "\n",
    "def evaluate_responses_with_sentiment(data):\n",
    "    # Perform sentiment analysis\n",
    "    data['sentiment'] = data['generated_response'].apply(\n",
    "        lambda x: analyze_sentiment(x))\n",
    "\n",
    "    # Perform emotion detection\n",
    "    emotion_scores = data['generated_response'].apply(\n",
    "        lambda x: detect_emotions(x))\n",
    "    data = pd.concat([data, emotion_scores.apply(pd.Series)], axis=1)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "# Apply the extended evaluation function\n",
    "evaluated_data = pd.read_csv(\n",
    "    '/Users/dipendrapant/Library/CloudStorage/OneDrive-NTNU/ForFun/npj_digital_medicine/code/data/result/v2/test_generated_responses.csv')\n",
    "# Apply the extended evaluation function\n",
    "evaluated_data_with_sentiment = evaluate_responses_with_sentiment(\n",
    "    evaluated_data)\n",
    "\n",
    "# Display some sentiment and emotion analysis results\n",
    "print(evaluated_data_with_sentiment[[\n",
    "      'generated_response', 'sentiment', 'pos', 'neu', 'neg', 'compound']].head())\n",
    "\n",
    "############ 7. Summarize Sentiment and Emotion Scores ############\n",
    "\n",
    "# Calculate overall sentiment score\n",
    "overall_sentiment = evaluated_data_with_sentiment['sentiment'].mean()\n",
    "print(f\"Overall Sentiment Score: {overall_sentiment}\")\n",
    "\n",
    "# Calculate average emotion scores\n",
    "average_emotions = evaluated_data_with_sentiment[[\n",
    "    'pos', 'neu', 'neg', 'compound']].mean()\n",
    "print(f\"Average Emotion Scores:\\n{average_emotions}\")\n",
    "\n",
    "# Plotting the emotion distributions\n",
    "plt.figure(figsize=(10, 6))\n",
    "average_emotions.plot(kind='bar', color=['green', 'blue', 'red', 'purple'])\n",
    "plt.title('Average Emotion Scores')\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Emotion')\n",
    "plt.xticks(rotation=0)\n",
    "# plt.savefig('/Users/dipendrapant/Library/CloudStorage/OneDrive-NTNU/ForFun/npj_digital_medicine/code/data/result/v2/emotion_scores.eps', format='eps', dpi=600)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dig_med",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
